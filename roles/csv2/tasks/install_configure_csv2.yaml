---
- set_fact:
    csv2_host: '{{ i_virtualhosts.0.virtualhost }}'
    ssl_cert_file: "/etc/letsencrypt/live/{{ i_service_connection.0.ipv4fqdn }}/fullchain.pem"
    ssl_key_file: "/etc/letsencrypt/live/{{ i_service_connection.0.ipv4fqdn }}/privkey.pem"
  when: (local_web is undefined) or (local_web == False)

- set_fact:
    csv2_host: localhost
    ssl_cert_file: /local_ssl/localhost.crt
    ssl_key_file: /local_ssl/localhost.key
  when: 
    - local_web is defined
    - local_web == True

- set_fact:
    ssl_ca_cert_arg: 'SSLCACertificatePath /etc/grid-security/certificates/'
  when: (container is undefined) or (container == False)

- set_fact:
    ssl_ca_cert_arg: 'SSLCACertificateFile /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem'
  when: 
    - container is defined
    - container == True

- set_fact:
    db_hostname: "{{ i_service_connection.0.ipv4fqdn }}"
  when:
    - (db_on_localhost is undefined) or (db_on_localhost != true)

- name: set_fact
  set_fact:
    db_hostname: "localhost"
  when:
    - db_on_localhost is defined
    - db_on_localhost == true

- name: set_fact
  set_fact:
    hostname: "{{ i_service_connection.0.ipv4fqdn }}"

- name: create cloudscheduler user
  user:
    name: cloudscheduler

- name: change the group ownership of the phpmyadmin directories
  file:
    dest: "{{ item }}"
    state: directory
    group: cloudscheduler
    mode: "0774"
  with_items:
    - /etc/phpMyAdmin
    - /var/log/php-log
    - /run/php-fpm
  when:
    - (install_phpMyAdmin is defined) and (install_phpMyAdmin == True)

- name: Change the group ownership of the /var/lib/php and all subfiles
  ansible.builtin.file:
    dest: /var/lib/php
    state: directory
    group: cloudscheduler
    mode: "0774"
    recurse: true
  when: (install_phpMyAdmin is defined) and (install_phpMyAdmin == True)

- name: Register php log files
  ansible.builtin.find:
    paths: /var/log/php-fpm/
    patterns: "*.log"
  register: php_logs
  when: (install_phpMyAdmin is defined) and (install_phpMyAdmin == True)

- name: Change the group ownership of php log files
  ansible.builtin.file:
    path: "{{ item.path }}"
    state: file
    group: cloudscheduler
    mode: "0664"
  loop: "{{ php_logs.files }}"
  when: (install_phpMyAdmin is defined) and (install_phpMyAdmin == True)

- name: change the group ownership of the phpmyadmin configuration file
  file:
    dest: "{{ item }}"
    state: file
    group: cloudscheduler
  with_items:
    - /etc/phpMyAdmin/config.inc.php
  when:
    - (install_phpMyAdmin is defined) and (install_phpMyAdmin == True)

### install software ###########################################################################################################################################

- name: import_tasks
  import_tasks: install_python3_mod_wsgi.yaml

- name: get the script for rabbitmq
  get_url:
    url: https://packagecloud.io/install/repositories/rabbitmq/rabbitmq-server/script.rpm.sh
    dest: /tmp/rabbitmq_script.rpm.sh
    mode: a+x
  when: ansible_facts['distribution_major_version'] == '9'

- name: execute the script
  shell: sudo os=el dist=8 /tmp/rabbitmq_script.rpm.sh
  when: ansible_facts['distribution_major_version'] == '9'

- name: get the erlang script
  get_url:
    url: https://packagecloud.io/install/repositories/rabbitmq/erlang/script.rpm.sh
    dest: /tmp/erlang_script.rpm.sh
    mode: a+x
  when: ansible_facts['distribution_major_version'] == '9'

- name: execute the script
  shell: sudo os=el dist=8 /tmp/erlang_script.rpm.sh
  when: ansible_facts['distribution_major_version'] == '9'

- name: install other prerequisite packages for cloudscheduler
  yum:
    name:
      - libvirt
      - libvirt-devel
      - ca_policy_igtf-classic
      - apr-util-mysql
      - rabbitmq-server
    state: latest

- name: install ansible (still uses python 2.7) module prerequisites
  yum:
    name: python*-bcrypt

- name: install qemu-img
  yum:
    name: qemu-img

- name: install virt-sparsify
  yum:
    name: libguestfs-tools-c

- name: upgrade pip3 setuptools
  pip:
    name:
      - pip
      - setuptools
    executable: pip3
    state: latest

- name: determine django package version
  set_fact:
    django_package: "{{ 'django' if ansible_facts['distribution_major_version'] == '9' else 'django==2.0.5'}}"

- name: do csv2, web frontend and pollers pip3 installs
  pip:
    name: ["bcrypt==3.1.4", "boto3>=1.9.130", "pika", "python-keystoneclient",
           "openstacksdk==0.57.0", "python-dateutil",
           "pyyaml", "jinja2", "libvirt-python", "py-dateutil", "urllib3", "django-mathfilters",
           "htcondor", "PyMySQL", "psutil", "celery", "{{ django_package }}",
           "django-debug-toolbar", "python-magic"]
    executable: pip3
#### Removed mqsqlclient and mqsql-connector and sqlparse "mysqlclient==1.3.1", "mysql-connector==2.2.9", "sqlparse==0.2.4"
#### previously used celery==4.4.6 but there was a metadata issue so now using latest

- name: install mysql python packages
  pip:
    name: ["mysqlclient", "mysql-connector", "sqlparse"]
    executable: pip3

- name: save any changes in the git repository that we are about to pull down
  git_reposave:
    dest: /opt/cloudscheduler/
  ignore_errors: yes

- name: pull down git repository
  git:
    repo: 'https://github.com/hep-gc/cloudscheduler.git'
    dest: /opt/cloudscheduler/
    force: yes
    update: yes
    version: "{{ cs_git_branch }}"

- name: Mark all directories as safe in /etc/gitconfig
  ansible.builtin.command:
    cmd: git config --system --add safe.directory '*'

- name: install ace js code editor
  git:
    repo: 'https://github.com/ajaxorg/ace-builds.git'
    dest: /opt/cloudscheduler/web_frontend/cloudscheduler/csv2/static/ace-builds/
    accept_hostkey: yes
    force: yes
    update: no
    version: master

# Installing plotly via git clone was working intermittently previously and was only changed due to curl errors (92, 56)
# that may be indicative of a network issue. This may not actually require a change.
# - name: install plotly js graphing package
#   git:
#       repo: 'https://github.com/plotly/plotly.js.git'
#       dest: /opt/cloudscheduler/web_frontend/cloudscheduler/csv2/static/plotly.js/
#       accept_hostkey: yes
#       force: yes
#       update: no
#       version: master      

- name: Download plotly zip
  ansible.builtin.uri:
    dest: /root/Downloads/plotlytest.zip
    url: https://codeload.github.com/plotly/plotly.js/zip/refs/heads/master

- name: Unarchive plotly
  ansible.builtin.unarchive:
    remote_src: true
    dest: /opt/cloudscheduler/web_frontend/cloudscheduler/csv2/static/
    src: /root/Downloads/plotlytest.zip

- name: Rename unzipped plotly directory
  ansible.builtin.command: mv /opt/cloudscheduler/web_frontend/cloudscheduler/csv2/static/plotly.js-master /opt/cloudscheduler/web_frontend/cloudscheduler/csv2/static/plotly.js
  args:
    creates: /opt/cloudscheduler/web_frontend/cloudscheduler/csv2/static/plotly.js
    removes: /opt/cloudscheduler/web_frontend/cloudscheduler/csv2/static/plotly.js-master

- name: list current csv2 services
  shell:
    cmd: "for i in $(ls csv2-*.service.afile); do echo ${i::-6}; done"
    chdir: /opt/cloudscheduler/etc/systemd/system/
  register: current_csv2_services

- name: create/update csv2 service files in systemd directory
  copy:
    remote_src: yes
    src: "/opt/cloudscheduler/etc/systemd/system/{{ item }}.afile"
    dest: "/etc/systemd/system/{{ item }}"
    owner: root
    group: root
    mode: 0644
  with_items: "{{ current_csv2_services.stdout_lines }}"

- name: reload daemons 
  command: systemctl daemon-reload

- name: remove obsolete files
  file:
    path: "{{ item }}"
    state: absent
  with_items:
    - /etc/condor/config.d/gsi.container
    - /etc/cron.d/copy-letsencrypt-to-users
    - /etc/cron.d/copy_letsencrypt_to_users.sh
    - /etc/cron.d/csv2-copy-certificates-to-users
    - /etc/cron.d/create_condor_proxies
    - /etc/cron.d/csv2-ec2-instance-types
    - /etc/httpd/conf.d/welcome.conf
    - /etc/systemd/system/csv2-glint.service
    - /etc/logrotate.d/cspollers.conf
    - /etc/logrotate.d/csv2-pollers
    - /var/local/cloudscheduler/etc/condor/config.d/htcondor_distinguished_names
    - /var/lib/condor/.globus

### configure amqp #############################################################################################################################################

- name: prerequisite services are enabled and running
  systemd:
    name: "{{ item }}"
    enabled: yes
    state: restarted
  with_items:
    - rabbitmq-server

- name: wait for prerequisite services
  wait_for:
  args:
    timeout: 5

- name: define csv2 amqp (rabbitmq) users
  rabbitmq_user:
    user: "{{ item }}"
    password: "new user temporary password"
    vhost: /
    configure_priv: .*
    read_priv: .*
    write_priv: .*
    state: present
  with_items:
    - "{{ amqp_users }}"

- name: update csv2 amqp (rabbitmq) user passwords (cannot make "rabbitmq_user" work with "update_password=always" and "with_items")
  command: "rabbitmqctl change_password {{ item }} {{ amqp_user_passwords[item] }}"
  with_items:
    - "{{ amqp_users }}"

### httpd ######################################################################################################################################################

- name: recreate favicon link.
  file:
    src: "/opt/cloudscheduler/images/cs_{{ favicon_colour }}.ico"
    dest: "/opt/cloudscheduler/web_frontend/cloudscheduler/csv2/static/img/favicon.ico"
    state: link
    force: yes
  notify:
    restart httpd

- name: test apache user
  shell: grep -c "^User cloudscheduler" /etc/httpd/conf/httpd.conf || true
  register: config_apache_user

- name: run apache under the cloudscheduler user
  lineinfile:
    path: "/etc/httpd/conf/httpd.conf"
    regexp: '^User apache'
    line: "User cloudscheduler"
  notify:
    restart httpd
  when:
    config_apache_user.stdout == "0"

- name: test apache group
  shell: grep -c "^Group cloudscheduler" /etc/httpd/conf/httpd.conf || true
  register: config_apache_group

- name: run apache under the cloudscheduler group
  lineinfile:
    path: "/etc/httpd/conf/httpd.conf"
    regexp: '^Group apache'
    line: "Group cloudscheduler"
  notify:
    restart httpd
  when: config_apache_group.stdout == "0"

- name: allow proxy certificates
  copy:
    remote_src: yes
    src: /opt/cloudscheduler/etc/sysconfig/httpd.afile
    dest: /etc/sysconfig/httpd
    owner: root
    group: root
    mode: 0644
  notify:
    restart httpd

- name: set django setttings
  template:
    src: "opt_cloudscheduler_web_frontend_cloudscheduler_cloudscheduler_web_settings.py.j2"
    dest: /opt/cloudscheduler/web_frontend/cloudscheduler/cloudscheduler_web/settings.py
  notify:
    restart httpd

- name: set cloudscheduler apache config
  template:
    src: "etc_httpd_conf.d_csv2_ssl.conf.j2"
    dest: /etc/httpd/conf.d/csv2_ssl.conf
  notify:
    restart httpd

- name: Remove httpd config files from letsencrypt
  ansible.builtin.file:
    path: "{{ item }}"
    state: absent
  loop:
    - /etc/httpd/conf.d/elephant98.heprc.uvic.ca.conf
    - /etc/httpd/conf.d/elephant98.heprc.uvic.ca-le-ssl.conf

### HAProxy ####################################################################################################################################################

- name: Install haproxy
  ansible.builtin.dnf:
    name: haproxy
    state: latest

- name: Install haproxy config file
  ansible.builtin.template:
    src: etc_haproxy_haproxy.cfg.j2
    dest: /etc/haproxy/haproxy.cfg
    owner: root
    group: root
    mode: "0644"

- name: reload daemons 
  command: systemctl daemon-reload

- name: Ensure haproxy service is enabled and running
  systemd:
    name: haproxy.service
    enabled: true
    state: restarted

### container configuration ####################################################################################################################################

- name: set start condition in default.yaml.j2 for container target
  lineinfile:
    path: /opt/cloudscheduler/default.yaml.j2
    regexp: '^        START = '
    line: '        START = TRUE'
  when: 
    - container is defined
    - container == True
    - (openstack_vm is not defined) or (openstack_vm == False)

- name: Get public IP address
  ipify_facts:
  when:
    - container is defined
    - container == True

- name: update cloudscheduler to remove ssl verification for private-web container target
  lineinfile:
    path: /opt/cloudscheduler/cli/bin/csv2_common.py
    insertafter: "^            {{ item.req1 }}=\\(gvar\\['user_settings'\\]\\['{{ item.req2 }}'\\]"
    line: '            verify=False,'
  with_items:
    - { req1: 'cert', req2: 'server-grid-cert' }
    - { req1: 'auth', req2: 'server-user' }
  when:
    - container is defined
    - container == True
    - local_web is defined
    - local_web == True

- name: suppress python requests warning if ssl verification removed from cloudscheduler
  blockinfile:
    path: /opt/cloudscheduler/cli/bin/csv2_common.py
    insertafter: '^    import requests as py_requests'
    content: |2
          import urllib3
          urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

  when:
    - container is defined
    - container == True
    - local_web is defined
    - local_web == True

- name: set default settings for cloudsheduler command
  command: "cloudscheduler defaults set -s default -su csv2_default -spw {{ csv2_default_password }} -sa {{ csv2_web_address}}"
  when:
    - container is defined
    - container == True
    - local_web is defined
    - local_web == True

- name: ensure mysql pid is down
  shell: pkill -9 mysql
  ignore_errors: yes
  when: 
    - container is defined
    - container == True
    - (openstack_vm is not defined) or (openstack_vm == False)

### celery #####################################################################################################################################################

- name: create celery log directory
  file:
    state: directory
    path: /var/log/celery
    owner: cloudscheduler
    group: cloudscheduler
    mode: 0775

- name: touch celery log files before run
  file:
    state: touch
    path: "/var/log/celery/w{{ item }}.log"
    owner: cloudscheduler
    group: cloudscheduler
    mode: "0664"
  with_sequence: start=1 end=4

- name: create celery run directory
  file:
    state: directory
    path: /var/run/celery
    owner: cloudscheduler
    group: cloudscheduler
    mode: "0775"

- name: touch celery pid files before run
  file:
    state: touch
    path: "/var/run/celery/w{{ item }}.pid"
    owner: cloudscheduler
    group: cloudscheduler
    mode: "0664"
  with_sequence: start=1 end=4

### cloudscheduler #############################################################################################################################################

# this task may be able to be skipped as it is handled with a certbot deploy hook
- name: import_tasks
  import_tasks: copy_certificates_to_users.yaml

- name: import_tasks
  import_tasks: configure_EL7_HTCondor.yaml

- name: Open ports required for influxdb
  ansible.posix.firewalld:
    zone: public
    state: enabled
    permanent: true
    port: "{{ item }}"
  loop:
    - 8086/tcp        # influxdb
  ignore_errors: true
  notify: restart firewalld

- name: Flush firewalld handlers
  ansible.builtin.meta: flush_handlers

- name: create influx admin user
  command: influx -execute "CREATE USER admin WITH PASSWORD '{{ influx_admin_pass }}' WITH ALL PRIVILEGES"
  ignore_errors: yes

- name: install influxDB ssl configuration file
  copy:
    src: etc_influxdb_influxdb.conf
    dest: /etc/influxdb/influxdb.conf

- name: Start service InfluxDB
  service:
    name: influxdb
    state: restarted

- name: Create cloudscheduler config directory
  file:
      path=/etc/cloudscheduler
      state=directory
      owner=root
      group=cloudscheduler

- name: make a copy of the cloudscheduler.yaml file if it exists
  copy:
    remote_src: yes
    src: /etc/cloudscheduler/cloudscheduler.yaml
    dest: "/etc/cloudscheduler/cloudscheduler.yaml.old-{{ ansible_date_time.date }}"
  ignore_errors: yes

- name: install cloudscheduler.yaml config file
  template:
    src: "etc_cloudscheduler_cloudscheduler.yaml.j2"
    dest: /etc/cloudscheduler/cloudscheduler.yaml
    owner: root
    group: cloudscheduler
    mode: "0640"
  notify:
      restart httpd

- name: install celery config
  copy:
    remote_src: yes
    src: "/opt/cloudscheduler/etc/cloudscheduler/{{ item }}.afile"
    dest: "/etc/cloudscheduler/{{ item }}"
    owner: root
    group: root
    mode: "0644"
  with_items:
    - celery

- name: create cloudscheduler run time and log directory
  file: 
    path: "{{ item }}"
    owner: cloudscheduler
    group: cloudscheduler
    mode: "0774"
    state: directory
  with_items:  
    - /var/local/cloudscheduler/ec2
    - /var/local/cloudscheduler/image_cache
    - /var/local/cloudscheduler/run
    - /var/local/cloudscheduler/schema_backups
    - /var/local/cloudscheduler/signals
    - /var/log/cloudscheduler

- name: create empty cloudscheduler log files (owner=cloudscheduler, group=cloudscheduler)
  file:
    path: "/var/log/cloudscheduler/{{ item }}"
    owner: cloudscheduler
    group: cloudscheduler
    mode: "0644"
    state: touch
  with_items:
    - csv2_web.log
    - ec2Poller.log
    - main.log
    - openstackpoller.log
    - timeseriesPoller.log
    - watch_csv2.logging

- name: Create condor poller log file
  ansible.builtin.file:
    path: "/var/log/cloudscheduler/condor_poller.log"
    owner: condor
    group: condor
    mode: "0644"
    state: touch

- name: create empty cloudscheduler log files (owner=root, group=root)
  file:
    path: "/var/log/cloudscheduler/{{ item }}"
    owner: root
    group: root
    mode: "0644"
    state: touch
  with_items:
    - vm_data.logging

- name: copy logrotate files
  copy:
    remote_src: yes
    src: "/opt/cloudscheduler/etc/logrotate.d/{{ item }}.afile"
    dest: "/etc/logrotate.d/{{ item }}"
    owner: root
    group: root
    mode: "0644"
  with_items:
    - csv2-log
    - csv2-condor
    - csv2-vm-data
    - csv2-signals


- name: install csv2 sudoers
  copy:
    remote_src: yes
    src: "/opt/cloudscheduler/etc/sudoers.d/{{ item }}.afile"
    dest: "/etc/sudoers.d/{{ item }}"
    owner: root
    group: root
    mode: "0644"
  with_items:
    - cloudscheduler
    - condor

- name: ensure csv2 services are stopped
  systemd:
    name: "{{ item }}"
    enabled: yes
    state: stopped
  with_items: "{{ current_csv2_services.stdout_lines }}"  

- name: configure mariadb server
  copy:
    remote_src: yes
    src: /opt/cloudscheduler/etc/my.cnf.d/server.cnf.afile
    dest: /etc/my.cnf.d/server.cnf
    owner: root
    group: root
    mode: "0644"

- name: ensure mariadb is running
  systemd:
    name: mariadb
    state: restarted

- name: install csv2 database schema
  command: "/opt/cloudscheduler/utilities/db_upgrade {{ schema_model }} -i {{ db_upgrade_file }} -r live"
  register: db_upgrade

- name: retrieve privileges for remote users
  command: "/opt/cloudscheduler/utilities/mysql_privileges {{ item.0 }},{{ item.1 }} {{ item.2 }}"
  register: "mysql_privileges"
  with_list: "{{ remote_database_users }}"

- name: set_fact
  set_fact:
    stderr_lines: []
  when: mysql_privileges is defined

- name: set_fact
  set_fact:
    stderr_lines: "{{ stderr_lines + item.stderr_lines }}"
  with_items: "{{ mysql_privileges.results }}"
  when: mysql_privileges is defined

- name: debug
  debug:
    msg: "{{ item }}"
  with_nested: "{{ stderr_lines }}"
  when: mysql_privileges is defined

- name: set_fact
  set_fact:
    stdout_lines: []
  when: mysql_privileges is defined

- name: set_fact
  set_fact:
    stdout_lines: "{{ stdout_lines + item.stdout_lines }}"
  with_items: "{{ mysql_privileges.results }}"
  when: mysql_privileges is defined

- name: define csv2 database remote users and priveleges
  command: "mysql -u root -p'{{ database_user_passwords['root'] }}' -e '{{ item }}' csv2"
  with_items: "{{ stdout_lines }}"
  when: mysql_privileges is defined

- name: generate schema
  command: /opt/cloudscheduler/utilities/generate_schema.py
  notify: restart httpd

- name: set_fact
  set_fact:
    csv2_default_password: '{{ csv2_default_password }}'
  when: (container is undefined) or (container == False)

- name: set_fact
  set_fact: 
    condor_manager: '{{ inventory_hostname }}'

- name: set_fact
  set_fact:
    csv2_web_address: "https://{{ inventory_hostname }}"
  when: (local_web is undefined) or (local_web == False)

- name: set_fact
  set_fact:
    csv2_web_address: https://localhost
  when: 
    - container is defined
    - container == True
    - local_web is defined
    - local_web == True
    - (running_condor is undefined) or (running_condor == True)

- name: set_fact
  set_fact:
    csv2_web_address: https://localhost
  when:
    - container is defined
    - container == True
    - local_web is defined
    - local_web == True
    - running_condor is defined
    - running_condor == False

- name: encrypt the default user password
  blowfish:
    password: "{{ csv2_default_password }}"

- name: determine mysql command 
  set_fact:
    mysql_command: "{{ 'mariadb' if ansible_facts['distribution_major_version'] == '9' else 'mysql' }}"

- name: create csv2_default user for csv2
  command: "{{ mysql_command }} -u root --password=\"{{ database_user_passwords['root'] }}\" -D csv2 -e 'INSERT INTO csv2_user (username, password, is_superuser, join_date) VALUES (\"csv2_default\", \"{{ blowfish.hash }}\", 1, \"2018-04-01\")'"
  ignore_errors: yes

- name: create csv2-group for the default csv2 user
  command: "{{ mysql_command }} -u root --password=\"{{ database_user_passwords['root'] }}\" -D csv2 -e 'INSERT INTO csv2_groups (group_name, htcondor_fqdn, job_cpus, job_ram, job_disk, job_scratch, job_swap, vm_keep_alive) VALUES (\"csv2-group\", \"{{ condor_manager }}\", \"1\", \"1000\", \"5\", \"0\", \"0\", \"0\")'"
  ignore_errors: yes

- name: add default csv2 user to csv2-group
  command: "{{ mysql_command }} -u root --password=\"{{ database_user_passwords['root'] }}\" -D csv2 -e 'INSERT INTO csv2_user_groups (username, group_name) VALUES (\"csv2_default\", \"csv2-group\")'"
  ignore_errors: yes

- name: add metadata files for csv2-group
  command: "{{ mysql_command }} -u root --password=\"{{ database_user_passwords['root'] }}\" -D csv2 -e 'INSERT INTO csv2_group_metadata (group_name, metadata_name, enabled, priority, metadata, mime_type) VALUES (\"csv2-group\", \"{{ item }}\", \"1\", \"0\", LOAD_FILE(\"/opt/cloudscheduler/metadata/{{ item }}\"), \"cloud-config\")'"
  ignore_errors: yes
  with_items:
    - default.yaml.j2

- name: ensure public index file exists
  copy:
    content: ""
    dest: /opt/cloudscheduler/public/index.html
    force: yes
    group: cloudscheduler
    owner: cloudscheduler
    mode: "0775"

- name: ensure public last update file exists
  copy:
    content: "0"
    dest: /var/local/cloudscheduler/public_last_update.txt
    force: yes
    group: cloudscheduler
    owner: cloudscheduler
    mode: "0775"

- name: generate original public page
  command: python3 /opt/cloudscheduler/web_frontend/cloudscheduler/csv2/gen_public_page.py
  become: yes
  become_user: cloudscheduler

- name: copy csv2 crontab entries
  copy:
    remote_src: yes
    src: "/opt/cloudscheduler/etc/cron.d/{{ item }}.afile"
    dest: "/etc/cron.d/{{ item }}"
    owner: root
    group: root
    mode: "0644"
  with_items:
    - csv2-signal-log-cleanup
    - csv2-watch
    - generate-public-page

- name: make a soft link to the cloudscheduler executable
  file:
    src: "/opt/cloudscheduler/cli/bin/cloudscheduler"
    dest: /usr/bin/cloudscheduler
    state: link


- name: create influx reader user
  command: influx -ssl -unsafeSsl -database 'csv2_timeseries' -username admin -password {{ influx_admin_pass }} -execute "CREATE USER csv2_read WITH PASSWORD 'csv2_public'"
  ignore_errors: yes

- name: check if the writer user exists
  shell: influx -ssl -unsafeSsl -database 'csv2_timeseries' -username admin -password {{ influx_admin_pass }} -execute 'SHOW USERS' | grep csv2_writer | wc -l
  register: csv2_writer_user

- name: create influx writer user
  command: influx -ssl -unsafeSsl -database 'csv2_timeseries' -username admin -password {{ influx_admin_pass }} -execute "CREATE USER csv2_writer WITH PASSWORD '{{ influx_writer_pass }}'"
  ignore_errors: yes
  when: csv2_writer_user.stdout == '0'

- name: set permissions for influx read user
  command: influx -ssl -unsafeSsl -database 'csv2_timeseries' -username admin -password {{ influx_admin_pass }} -execute "GRANT READ ON csv2_timeseries TO csv2_read"
  ignore_errors: yes

- name: set permissions for influx write user
  command: influx -ssl -unsafeSsl -database 'csv2_timeseries' -username admin -password {{ influx_admin_pass }} -execute "GRANT WRITE on csv2_timeseries TO csv2_writer"
  ignore_errors: yes

- name: restart influxdb on ssl
  service:
    name: influxdb
    state: restarted

- name: ensure csv2 services are enabled and running
  systemd:
    name: "{{ item }}"
    enabled: yes
    state: restarted
  with_items: "{{ current_csv2_services.stdout_lines }}"

- name: Create new default group "default"
  ansible.builtin.command: >-
    cloudscheduler group add
    -su csv2_default
    -spw '{{ csv2_default_password }}'
    -sa {{ csv2_web_address }}
    -gn default
    -un csv2_default
    -htcf {{ condor_manager }}
  register: default_out
  failed_when:
    - default_out.rc != 0
    - "'HTTP response code' in default_out.stdout"
  changed_when:
    - "'successfully added' in default_out.stdout"

- name: Remove old setup group csv2_default
  ansible.builtin.command: >-
    cloudscheduler group delete
    -su csv2_default
    -spw '{{ csv2_default_password }}'
    -sa {{ csv2_web_address }}
    -gn csv2-group
    -Y
  register: csv2_default_out
  failed_when:
    - csv2_default_out.rc != 0
    - "'HTTP response code' in csv2_default_out.stdout"
  changed_when:
    - "'succesfully deleted' in csv2_default_out.stdout"

- name: TEST STEP DISABLE EC2
  systemd:
    name: csv2-ec2
    state: stopped
    enabled: yes

- name: Flush handlers
  ansible.builtin.meta: flush_handlers
...
